---
title: "Programming Assignment 4"
subtitle: 'Program'
author  : "Kyle Parrish"
date    : "Rutgers University</br>Spring 2021</br>Last update: `r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: assets
    css: ["rutgers"]
    nature:
      beforeInit: 
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
    
---

```{css, echo = FALSE}
.remark-slide-content {
  font-size: 20px;
  padding: 20px 80px 20px 80px;
}
.remark-code, .remark-inline-code {
  background: #f0f0f0;
}
.remark-code {
  font-size: 24px;
}
.huge .remark-code { /*Change made here*/
  font-size: 200% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 70% !important;
}


```

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.height = 6, fig.width = 7)
```

```{r setup, include=FALSE}
library(readr)
library(openintro)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(e1071)
library(sjPlot)
library(sjmisc)
library(sjlabelled)
library("lawstat")
library("ggfortify")
library("lmtest")
library("DataCombine")
library("gvlma")
library("tidyverse")
library(xaringanthemer)
library(showtext)

```


```{r load data, include = FALSE}

fricatives <- read_csv("../data_raw/fricatives.csv")

```

# PA4 

--

- This was an awesome assignment to tie everything together.

--

- This presentation will show you my experience of this PA. But first...

--

- You will look at a picture of my dogs. 

--

- This is **unavoidable.** 

---

# Olive, Kevin, and Phyllis. 
![Majestic animals](assets/img/dawgs.jpg)


---

# Now we get started 

Here is the general layout of this presentation in 6 total parts.  

--

(1) Pondering how to tidy

--

(2) Descriptive statistics 

--

(3) Plots 

--

(4) Modeling 

--

(5) Checking Model Assumptions

--

(6) Written Summary 

---

# Pondering how to tidy 

I am using the function `skewness` to see if this vector's data is skewed. A value between -0.5 and -1 suggest that it is moderately skewed, meaning that it does not follow a normal distribution. Joseph was being tricky.

```{r, echo=FALSE}
skewness(fricatives$s_cog)
skewness(fricatives$s_skewness)
skewness(fricatives$sh_cog)
skewness(fricatives$sh_skewness)
```

---

# Pondering how to tidy 

But why might the data be skewed? Time to check out the data and see if this skewness actually matters.  

---

# Pondering how to tidy 

First, we will eye-ball it. It looks like there is a linear relationship here, but there is at least a single point that might be an influential data point. 

```{r, echo = FALSE, fig.height= 6, fig.width = 7}

ggplot(data = fricatives, aes(x = s_cog, y = s_skewness)) + geom_point(color = "Steelblue3") + ggtitle("Eye-ball it graph: is there a linear relationship bewteen skewness and COG?") + xlab("Center of Gravity") + ylab("Skewness")

```

---


# Descriptive Statistics 

Here are some descriptive stats - after tidying, a dataframe showing the means and standard deviations of COG and skewness for /s/ and /Êƒ/ was created. I saved the output of the tidy file and descriptive table under the `data_tidy` folder. 

```{r, echo=FALSE, warning=FALSE, }

fricatives_tidy = fricatives %>% 
  pivot_longer(c(`s_cog`, `s_skewness`,`sh_cog`, `sh_skewness`), names_to = "type", values_to = "value") %>% 
  separate(type, into = c("phoneme", "measure"), sep = "_") %>% 
  pivot_wider(names_from = measure, values_from = value)


fricatives_tidy %>% 
  write.csv("../data_tidy/fricatives_tidy")

fricatives_desc = fricatives %>% 
  pivot_longer(c(`s_cog`, `s_skewness`,`sh_cog`, `sh_skewness`), names_to = "type", values_to = "value") %>%
  separate(type, into = c("phoneme", "measure"), sep = "_") %>%
  group_by(phoneme, measure) %>% 
  summarise(mean = mean(value), sd = sd(value)) 

fricatives_desc %>% 
  write.csv("../data_tidy/fricatives_desc")


knitr::kable(fricatives_desc, digits = 3)

```
---

# Plots 

Here is the box plot in all its beauty. 

```{r, echo = FALSE, fig.height= 6, fig.width = 7}
fricatives_tidy %>%
  ggplot(., aes(x = phoneme, y = cog)) + geom_boxplot(fill = "deepskyblue3") + xlab("Phoneme") + ggtitle("COG as a function of phoneme") + ylab("Center of Gravity")

```

---

# Plots

Here is the other plot.

```{r, echo = FALSE, fig.height= 6, fig.width = 7}

fricatives_tidy %>%
  ggplot(., aes(x = phoneme, y = skewness)) + stat_summary(fun.data = "mean_cl_boot") + geom_point(alpha = .3, color = "seagreen") + ggtitle("Skewness as a function of phoneme") + xlab("Skewness") + ylab("Phoneme")
                                                                      
```
---

# Modeling

Now, I turn to modeling. This model is a bivariate regression which examines center of gravity as a function of skewness for the [s] segments.

Hey, it looks like skewness is a significant predictor of cog `p = 7.69e-10`, and explains quite a bit of variance (`Multiple R-squared:  0.8836`,	`Adjusted R-squared:  0.8771`). 

.tiny[
```{r}

fricatives_s = fricatives_tidy %>% 
  filter(phoneme == "s")


model = lm(fricatives_s$cog ~ fricatives_s$skewness)


tab_model(model)
```
]
---

# Modeling

```{r, include=FALSE}
mean(model$residuals)

```

The **mean** of the residuals was `1.136591e-14` - this is close to 0, so it checks out.

--

But... other parts of the residuals are suspicious.

--
However, the **quantiles** and **median** are cause for concern, being that 1Q is `-21.72` and 3Q is `123` - these should be similar absolute values. Likewise, the median is `58.96` - it should also be around 0. Somethings afoot. 

.tiny[
```{r}

summary(model)

```
]

---

# Modeling 

--

Let's see if the `gvlma` functions says that the assumptions of the linear model are satisfied..


--

Dang! The `gvlma` function in R reveals that 5 assumptions of the linear model are **not** satisfied. 

.tiny[
```{r}

gvlma::gvlma(model)

```
]

---

# Modeling 

What could be the problem? Why does this model hate me?

--

That point that I thought was suspicious of might be to blame. 

--

Looking at Cook's Distance might let us know whether individual data points have high **leverage**.

--

The higher the leverage, the more one data point influences the regression line relative to other data points. 

--

---

# Modeling 

--

Looking at this graph of the leverage of each observation in this study suggests that there is not only one, but **two influential data points**, observations 1 and 20. 

--

```{r}

Leverage = cooks.distance(model)

plot(Leverage)

```

---

# Checking Model Assumptions

--

Let's check the other model assumptions and see how much trouble these two observations are causing. 

--

The residuals do not check out. Data point 20 is causing trouble everywhere. That rascal. 

```{r}
autoplot(model)

```

---

# Checking Model Assumptions

The predictor variable and the residuals are not correlated, so that's one less problem. 

.tiny[
```{r}

cor.test(fricatives_s$skewness, model$residuals)

```
]

---

# Checking Model Assumptions

The observations are also not autocorrelated. Neat.

```{r}

acf(model$residuals)

```
---


# Checking Model Assumptions 

Let's see if these influential data points are the cause - removing observations `1` and `20` from the data frame and re-checking the residuals. 

--

`Model2` looks pretty good... it also shows that skewness is a significant predictor of COG for [s]

--


.tiny[
```{r}

fricatives_s2 = fricatives_s %>% 
  filter(obs > 1 & obs < 20)

model2 = lm(fricatives_s2$cog ~ fricatives_s2$skewness)

tab_model(model2)
```
]
---

# Checking Model Assumptions 

--

Now that we have a new model, let's look at the mean of the residuals again.

--

The mean of the residuals was `6.810524e-15` and is close to zero, as it should be. 

--

That's pretty close to zero!

---

# Checking Model Assumptions 

Here is a summary of boths model together

.tiny[
```{r}


tab_model(model, model2)

```
]
---

# Checking Model Assumptions

These residuals look much better than last time. 

```{r}
autoplot(model2)

```

---

# Checking Model Assumptions 

Let's see whether the model assumptions are now satisfied...

--

All 5 assumptions are now satisfied! Observation 20 sucks.

--

.tiny[
```{r}

gvlma::gvlma(model2)

```
]
---

# Written Summary 

The data was analyzed using a bivariate linear regression model in R. A total of two models were run in which the outcome variable was center of gravity for [s] segments and the predictor variable was skewness for the [s] segments. In the first model, it was found that skewness was a significant predictor of center of gravity for [s] (p = <.001). However, the analysis of the residuals in the first model revealed that the model did not satisfy the assumptions of the linear model in that the data was skewed and too heteroscedastic. Upon further inspection of the residuals, two influential data points were identified and removed for the purpose of fitting a second model. It is assumed that these points were very distinct from the rest as a result of measurement error. The second model satisfied the assumptions of the linear model and retained a significant p-value (<.001).
