---
title: "Programming Assignment 4"
subtitle: 'Data Science for Linguists'
author  : "Kyle Parrish"
date    : "Rutgers University</br>Spring 2021</br>Last update: `r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: assets
    css: ["rutgers"]
    nature:
      beforeInit: 
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
    
---

```{css, echo = FALSE}
.remark-slide-content {
  font-size: 20px;
  padding: 20px 80px 20px 80px;
}
.remark-code, .remark-inline-code {
  background: #f0f0f0;
}
.remark-code {
  font-size: 24px;
}
.huge .remark-code { /*Change made here*/
  font-size: 200% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 70% !important;
}


```

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.height = 6, fig.width = 7)

```

```{r setup, include=FALSE}
library(readr)
library(openintro)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(e1071)
library(sjPlot)
library(sjmisc)
library(sjlabelled)
library("lawstat")
library("ggfortify")
library("lmtest")
library("DataCombine")
library("gvlma")
library("tidyverse")
library(xaringanthemer)
library(showtext)

```


```{r load data, include = FALSE}

fricatives <- read_csv("../data_raw/fricatives.csv")

```

# PA4 

--

- This was an awesome assignment to tie everything together.

--

- This presentation will show you my experience of this PA. But first...

--

- You will look at a picture of my dogs. 

--

- This is **unavoidable.** 

---

# Olive, Kevin, and Phyllis. 

```{r, out.width="65%"}

knitr::include_graphics("assets/img/dawgs.jpg")

```


---

# Now we get started 

Here is the general layout of this presentation in **6 total parts.**  

--

(1) Pondering how to tidy

--

(2) Descriptive statistics 

--

(3) Plots 

--

(4) Modeling 

--

(5) Checking Model Assumptions

--

(6) Written Summary 

---

# Pondering how to tidy 

I am using the function `skewness` to see if each vector's data is skewed. An absolute value between 0.5 and 1 suggest that it is moderately skewed, meaning that it does not follow a normal distribution. This seems to apply in three of our vectors. Profe was being tricky.

```{r, echo=FALSE}
skewness(fricatives$s_cog)
skewness(fricatives$s_skewness)
skewness(fricatives$sh_cog)
skewness(fricatives$sh_skewness)
```

---

# Pondering how to tidy 

But why might the data be skewed? Time to check out the data and see if this skewness actually matters.  

---

# Pondering how to tidy 

First, we will **eye-ball it**. This is a plot of center of gravity as a function of skewness. It looks like there is a linear relationship here, but there is at least a single point that might be an influential data point. (Bottom left corner)

```{r, echo = FALSE, fig.height= 6, fig.width = 7}

ggplot(data = fricatives, aes(x = s_cog, y = s_skewness)) + geom_point(color = "Steelblue3") + ggtitle("Eye-ball it graph: is there a linear relationship bewteen skewness and COG?") + xlab("Center of Gravity") + ylab("Skewness")

```

---


# Descriptive Statistics 

Here are some descriptive stats - after tidying, I created a dataframe showing the means and standard deviations of COG and skewness for [s] and [ʃ] segments. I saved the outputs of both the tidy file and the descriptive table under the `data_tidy` folder in my `pa4` repo.  

```{r, echo=FALSE, warning=FALSE, }

fricatives_tidy = fricatives %>% 
  pivot_longer(c(`s_cog`, `s_skewness`,`sh_cog`, `sh_skewness`), names_to = "type", values_to = "value") %>% 
  separate(type, into = c("phoneme", "measure"), sep = "_") %>% 
  pivot_wider(names_from = measure, values_from = value)


fricatives_tidy %>% 
  write.csv("../data_tidy/fricatives_tidy")

fricatives_desc = fricatives %>% 
  pivot_longer(c(`s_cog`, `s_skewness`,`sh_cog`, `sh_skewness`), names_to = "type", values_to = "value") %>%
  separate(type, into = c("phoneme", "measure"), sep = "_") %>%
  group_by(phoneme, measure) %>% 
  summarise(mean = mean(value), sd = sd(value)) 

fricatives_desc %>% 
  write.csv("../data_tidy/fricatives_desc")


knitr::kable(fricatives_desc, digits = 3)

```
---

# Plots 

Here is the box plot in all its beauty. From this visualization, it looks like cog is different in [s] and [ʃ] segments.

```{r, echo = FALSE, fig.height= 6, fig.width = 7}
fricatives_tidy %>%
  ggplot(., aes(x = cog, y = phoneme)) + geom_boxplot(fill = "deepskyblue3") + xlab("Phoneme") + ggtitle("COG as a function of phoneme") + ylab("Center of Gravity")

```

---

# Plots

Here is the other plot for skewness - made using `stat_summary` in `ggplot2`. Skewness also looks to be distinct in [s] and 

```{r, echo = FALSE, fig.height= 6, fig.width = 7}

fricatives_tidy %>%
  ggplot(., aes(x = phoneme, y = skewness)) + stat_summary(fun.data = "mean_cl_boot") + geom_point(alpha = .3, color = "seagreen") + ggtitle("Skewness as a function of phoneme") + xlab("Skewness") + ylab("Phoneme")
                                                                      
```
---

# Modeling

Now, I turn to modeling. This model is a bivariate regression which examines center of gravity as a function of skewness for the [s] segments.

Hey, it looks like skewness is a significant predictor of cog `p = 7.69e-10`, and explains quite a bit of variance (`Multiple R-squared:  0.8836`,	`Adjusted R-squared:  0.8771`). 

.tiny[
```{r}

fricatives_s = fricatives_tidy %>% 
  filter(phoneme == "s")


model = lm(cog ~ skewness, data = fricatives_s)


tab_model(model)
```
]
---

# Modeling

```{r, include=FALSE}
mean(model$residuals)

```

The **mean** of the residuals was `1.136591e-14` - this is close to 0, so it checks out.

--

But... other parts of the residuals are suspicious.

--

The **quantiles** and **median** are cause for concern, being that 1Q is `-21.72` and 3Q is `123` - these should be similar absolute values. Likewise, the median is `58.96` - it should also be around 0. Somethings afoot. 

.tiny[
```{r}

summary(model)

```
]

---

# Modeling 

--

Let's see if the `gvlma` functions says that the assumptions of the linear model are satisfied..


--

Dang! The `gvlma` function in R reveals that 5 assumptions of the linear model are **not** satisfied. 

.tiny[
```{r}

gvlma::gvlma(model)

```
]

---

# Modeling 

What could be the problem? Why does this model hate me?

--

That point that I thought was suspicious might be to blame. 

--

Looking at Cook's Distance might let us know whether individual data points have high **leverage**.

--

The higher the leverage, the more one data point influences the regression line relative to other data points. 

--

---

# Modeling 

--

Looking at this graph of the leverage of each observation in this study suggests that there is not only one, but **two influential data points**, observations 1 and 20. 

--

```{r}

Leverage = cooks.distance(model)

plot(Leverage)

```

---

# Checking Model Assumptions

--

Let's check the other model assumptions and see how much trouble these two observations are causing. 

--

The residuals do not check out. Data point 20 is causing trouble everywhere. That rascal. 

```{r}
autoplot(model)

```

---

# Checking Model Assumptions

Before dealing with this point, I want to also see whether there could be an issue with **autocorrelation** or whether there is **a correlation between the predictor variable (skewness) and the residuals of the model**. 

--

The predictor variable and the residuals are not correlated, so that's one less problem `(p = 1)`. 

.tiny[
```{r}

cor.test(fricatives_s$skewness, model$residuals)

```
]

---

# Checking Model Assumptions

The observations are also not autocorrelated. Neat.

```{r}

acf(model$residuals)

```
---


# Checking Model Assumptions 

Let's see if these influential data points are the cause - removing observations `1` and `20` from the data frame and re-checking the residuals. 

--

`Model2` looks pretty good... it also shows that skewness is a significant predictor of COG for [s]

--

It also explains more of the variance observed in the data than model1 `Multiple R-squared:  0.967`,	`Adjusted R-squared:  0.965`

--

.tiny[
```{r}

fricatives_s2 = fricatives_s %>% 
  filter(obs > 1 & obs < 20)

model2 = lm(cog ~ skewness, data = fricatives_s2)

tab_model(model2)
```
]
---

# Checking Model Assumptions 

--

Now that we have a new model, let's look at the mean of the residuals again.

--

Same as model1, the mean of the residuals was `6.810524e-15` and is close to zero, as it should be. 

--

The quantiles and median aren't as much cause for concern this time either. `1Q = -83.766`, `3Q = 65.884` and the `median = -3.425`. 


.tiny[
```{r}
summary(model2)

```
]
---

# Checking Model Assumptions 

Here is a summary of both models together - **model 1** is on the left and **model 2** is on the right. 

.tiny[
```{r}


tab_model(model, model2)

```
]
---

# Checking Model Assumptions

These residuals look much better than last time. 

```{r}
autoplot(model2)

```

---

# Checking Model Assumptions 

Let's see whether the model assumptions are now satisfied...

--

All 5 assumptions are now satisfied! Observation 20 sucks.

--

.tiny[
```{r}

gvlma::gvlma(model2)

```
]
---

# Checking Model Assumptions 

--

Now that the model is fits all assumptions, I will re-run descriptive stats for [s] and **report both models**.

--

Here is an updated descriptive chart, also saved under `data_tidy`, with the two influential datapoints `1` and `20` removed. 

--

```{r}
fricatives_desc2 = fricatives %>% 
  filter(obs < 20 & obs > 1) %>% 
  pivot_longer(c(`s_cog`, `s_skewness`,`sh_cog`, `sh_skewness`), names_to = "type", values_to = "value") %>%
  separate(type, into = c("phoneme", "measure"), sep = "_") %>%
  group_by(phoneme, measure) %>% 
  summarise(mean = mean(value), sd = sd(value)) 

fricatives_desc2 %>% 
  write.csv("../data_tidy/fricatives_desc2")


knitr::kable(fricatives_desc2, digits = 3)

fricatives_desc2 %>% 
  write.csv("../data_tidy/fricatives_desc2")
```
---

# Checking Model Assumptions 

--

Now let's look at the plot of both models together. As can be seen on the plot, the lines are different! The red points are the points that are unique to model1. 

--

```{r}

m_fricatives_s = fricatives_s%>% 
  mutate("model" = "model1")
m_fricatives_s2 = fricatives_s2 %>% 
  mutate("model" = "model2")

both_models_plot = rbind(m_fricatives_s, m_fricatives_s2)

both_models_plot %>% 
  ggplot(., aes(x = cog, y = skewness, color = model)) + geom_point() + geom_smooth(method = "lm", fullrange = TRUE) + ggtitle("Regression Lines for Model 1 and Model 2")



```

---

# Written Summary 

Here is my written summary, as I would have tried to write in a paper. 

--

`The data were analyzed using a bivariate linear regression model in R. 20 total observations were recording for [s] segments, in which center of gravity (cog) and skewness were recorded as continuous variables. A total of two models were run in which the outcome variable was center of gravity for [s] segments and the predictor variable was skewness for the [s] segments. In the first model, it was found that skewness was a significant predictor of center of gravity for [s] (p = <.001, Multiple R-squared =  0.8836, Adjusted R-squared = 0.8771). However, the analysis in R of the residuals of the first model, done by use of the functions *autoplot* and *gvlma*, suggested that this model did not satisfy the assumptions of the linear model. This analysis included a review of several plots, including a QQplot, a residuals vs. fitted plot, and plot of Cook's Distance of leverage. Upon further inspection of these plots, two influential data points were identified and removed for the purpose of fitting a second model. It is assumed that these points were very distinct from the rest as a result of measurement error. The second model satisfied the assumptions of the linear model and remained significant (p = <.001, Multiple R-squared = 0.967, 	Adjusted R-squared =  0.965). A reanalysis of the second model using *autoplot* and *gvlma* revealed that the assumptions of the linear model were satisfied following the removal of the two influential data points.` 
